{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4faab94b-8b0c-4b78-becd-ef8cfef5fbd4",
   "metadata": {},
   "source": [
    "# Generate embeddings from text files in the given directory and store in Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ebfe71-b8bc-4d46-8804-04d7f455acb3",
   "metadata": {},
   "source": [
    "This program indexes RFC text files in a local directory into a locally running Qdrant Vector DB.\n",
    "\n",
    "I downloaded RFCs from: https://www.rfc-editor.org/retrieve/bulk/\n",
    "\n",
    "I placed them in my directory `~/data/RFCs_8501_latest`. Removed the `*.pdf` and kept only `*.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffe92b4-7044-41a8-b35c-9bf16bc40860",
   "metadata": {},
   "source": [
    "Start [Qdrant](https://github.com/qdrant/qdrant) in your laptop:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "107d70ec-0a0a-4a02-a18c-395e957f1d1b",
   "metadata": {},
   "source": [
    "docker run -p 6333:6333 -p 6334:6334 \\\n",
    "    -v ${HOME}/data/qdrant:/qdrant/storage \\\n",
    "    qdrant/qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe58cbc9-91de-4fb8-a7a2-4bf6a6012e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qdrant-client in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (1.14.2)\n",
      "Requirement already satisfied: sentence_transformers in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (4.1.0)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from qdrant-client) (1.71.0)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from qdrant-client) (2.2.5)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from qdrant-client) (2.10.1)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from qdrant-client) (6.30.2)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from qdrant-client) (2.11.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from qdrant-client) (2.4.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from sentence_transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from sentence_transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from sentence_transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from sentence_transformers) (0.31.1)\n",
      "Requirement already satisfied: Pillow in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from sentence_transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from sentence_transformers) (4.13.2)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.9.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/opt/certifi/lib/python3.13/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (80.3.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from scikit-learn->sentence_transformers) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.4.2/libexec/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install qdrant-client sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3f3d0d8-fd85-444b-a5e5-119c98621535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully stored 389 text files as embeddings in Qdrant collection 'text_embeddings'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from typing import List, Dict, Any\n",
    "import qdrant_client\n",
    "from qdrant_client.http import models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def load_text_files(directory_path: str) -> Dict[str, str]:\n",
    "    \"\"\"Load all text files from a directory.\"\"\"\n",
    "    text_files = {}\n",
    "    for file_path in glob.glob(os.path.join(directory_path, \"*.txt\")):\n",
    "        file_name = os.path.basename(file_path)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_files[file_name] = file.read()\n",
    "    return text_files\n",
    "\n",
    "def generate_embeddings(texts: List[str], model_name: str = \"all-MiniLM-L6-v2\") -> List[List[float]]:\n",
    "    \"\"\"Generate embeddings for a list of texts using a sentence transformer model.\"\"\"\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embeddings = model.encode(texts)\n",
    "    return embeddings.tolist()\n",
    "\n",
    "def store_in_qdrant(\n",
    "    client: qdrant_client.QdrantClient,\n",
    "    collection_name: str,\n",
    "    texts: Dict[str, str],\n",
    "    embeddings: List[List[float]],\n",
    "    vector_size: int\n",
    ") -> None:\n",
    "    \"\"\"Store texts and their embeddings in Qdrant.\"\"\"\n",
    "    # Create collection if it doesn't exist\n",
    "    collections = client.get_collections().collections\n",
    "    collection_exists = any(collection.name == collection_name for collection in collections)\n",
    "    \n",
    "    if not collection_exists:\n",
    "        client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=models.VectorParams(\n",
    "                size=vector_size,\n",
    "                distance=models.Distance.COSINE\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Prepare points to upsert\n",
    "    points = []\n",
    "    for i, (file_name, text) in enumerate(texts.items()):\n",
    "        points.append(\n",
    "            models.PointStruct(\n",
    "                id=i,\n",
    "                vector=embeddings[i],\n",
    "                payload={\"file_name\": file_name, \"text\": text}\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Upsert points to the collection\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=points\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    directory_path = os.environ.get('HOME') + \"/data/RFCs_8501_latest\"\n",
    "    collection_name = \"text_embeddings\"\n",
    "    model_name = \"all-MiniLM-L6-v2\"  # You can use other models like \"all-mpnet-base-v2\" for better quality\n",
    "    \n",
    "    # Connect to Qdrant (local or cloud)\n",
    "    client = qdrant_client.QdrantClient(\n",
    "        url=\"http://localhost:6333\",  # Change this if using Qdrant Cloud\n",
    "        # api_key=\"your-api-key\"  # Uncomment and add your API key if using Qdrant Cloud\n",
    "    )\n",
    "    \n",
    "    # Load text files\n",
    "    text_files = load_text_files(directory_path)\n",
    "    \n",
    "    if not text_files:\n",
    "        print(\"No text files found in the specified directory.\")\n",
    "        return\n",
    "    \n",
    "    # Generate embeddings\n",
    "    file_names = list(text_files.keys())\n",
    "    texts = list(text_files.values())\n",
    "    embeddings = generate_embeddings(texts, model_name)\n",
    "    \n",
    "    # Get vector size from the generated embeddings\n",
    "    vector_size = len(embeddings[0])\n",
    "    \n",
    "    # Store in Qdrant\n",
    "    store_in_qdrant(client, collection_name, text_files, embeddings, vector_size)\n",
    "    \n",
    "    print(f\"Successfully stored {len(text_files)} text files as embeddings in Qdrant collection '{collection_name}'.\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542256c4-00f9-4dad-9b22-88e967243817",
   "metadata": {},
   "source": [
    "Next, search the Vector DB to most matched files for the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e83ec8-4f0f-4bdc-8f01-d3394c04980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 5 relevant documents:\n",
      "\n",
      "--- Result 1 ---\n",
      "File: rfc8514.txt\n",
      "Similarity score: 0.4574\n",
      "Preview: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internet Engineering Task Force (IETF)                          S. Bosch\n",
      "Request for Comments: 8514                               Open Xchange Oy\n",
      "Category: Standards Track                       ...\n",
      "\n",
      "--- Result 2 ---\n",
      "File: rfc8508.txt\n",
      "Similarity score: 0.4520\n",
      "Preview: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internet Engineering Task Force (IETF)                         S. Brandt\n",
      "Request for Comments: 8508                                       Verizon\n",
      "Category: Standards Track                       ...\n",
      "\n",
      "--- Result 3 ---\n",
      "File: rfc8970.txt\n",
      "Similarity score: 0.4264\n",
      "Preview: ﻿\n",
      "\n",
      "\n",
      "\n",
      "Internet Engineering Task Force (IETF)                        M. Slusarz\n",
      "Request for Comments: 8970                             Open-Xchange Inc.\n",
      "Category: Standards Track                        ...\n",
      "\n",
      "--- Result 4 ---\n",
      "File: rfc8579.txt\n",
      "Similarity score: 0.4140\n",
      "Preview: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internet Engineering Task Force (IETF)                          S. Bosch\n",
      "Request for Comments: 8579                               Open Xchange Oy\n",
      "Category: Standards Track                       ...\n",
      "\n",
      "--- Result 5 ---\n",
      "File: rfc8621.txt\n",
      "Similarity score: 0.3575\n",
      "Preview: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internet Engineering Task Force (IETF)                        N. Jenkins\n",
      "Request for Comments: 8621                                      Fastmail\n",
      "Updates: 5788                                   ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w4/c8trdbbj4d3c2660cqcynrtr0000gn/T/ipykernel_98102/1585881021.py:31: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = client.search( # deprecated, alternate use to be figured out!\n"
     ]
    }
   ],
   "source": [
    "import qdrant_client\n",
    "from qdrant_client.models import QueryRequest\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def search_documents(\n",
    "    query: str,\n",
    "    client: qdrant_client.QdrantClient,\n",
    "    collection_name: str,\n",
    "    model_name: str = \"all-MiniLM-L6-v2\",\n",
    "    limit: int = 5\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Search documents in Qdrant collection using semantic similarity.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query text\n",
    "        client: Qdrant client instance\n",
    "        collection_name: Name of the collection to search\n",
    "        model_name: Name of the embedding model (should match the one used for indexing)\n",
    "        limit: Maximum number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        List of matching documents with their metadata and similarity scores\n",
    "    \"\"\"\n",
    "    # Generate embedding for the query\n",
    "    model = SentenceTransformer(model_name)\n",
    "    query_embedding = model.encode(query).tolist()\n",
    "    \n",
    "    # Search in Qdrant\n",
    "    search_results = client.search( # deprecated, alternate use to be figured out!\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        limit=limit\n",
    "    )\n",
    "\n",
    "    # search_results = client.query_points(\n",
    "    #     collection_name=collection_name,\n",
    "    #     query=query_embedding,\n",
    "    #     limit=limit\n",
    "    # )\n",
    "    \n",
    "    # Format results\n",
    "    results = []\n",
    "    for result in search_results:\n",
    "        results.append({\n",
    "            \"file_name\": result.payload.get(\"file_name\"),\n",
    "            \"similarity_score\": result.score,\n",
    "            \"text_preview\": result.payload.get(\"text\", \"\")[:200] + \"...\" if len(result.payload.get(\"text\", \"\")) > 200 else result.payload.get(\"text\", \"\")\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    collection_name = \"text_embeddings\"\n",
    "    model_name = \"all-MiniLM-L6-v2\"  # Should match the model used for indexing\n",
    "    \n",
    "    # Connect to Qdrant\n",
    "    client = qdrant_client.QdrantClient(\n",
    "        url=\"http://localhost:6333\",  # Change this if using Qdrant Cloud\n",
    "        # api_key=\"your-api-key\"  # Uncomment and add your API key if using Qdrant Cloud\n",
    "    )\n",
    "    \n",
    "    # User input for search query\n",
    "    # query = input(\"Enter your search query: \")\n",
    "    query = \"imap\"\n",
    "    \n",
    "    # Search documents\n",
    "    results = search_documents(\n",
    "        query=query,\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    if results:\n",
    "        print(f\"\\nFound {len(results)} relevant documents:\")\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\n--- Result {i} ---\")\n",
    "            print(f\"File: {result['file_name']}\")\n",
    "            print(f\"Similarity score: {result['similarity_score']:.4f}\")\n",
    "            print(f\"Preview: {result['text_preview']}\")\n",
    "    else:\n",
    "        print(\"No matching documents found.\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58db4d4a-4520-49c2-89f4-282120e13cad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
